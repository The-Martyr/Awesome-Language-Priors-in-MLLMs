# Awesome-Language-Priors-in-MLLMs

This is a repository for organizing papres related to language priors of Multimodal Large Language Models (MLLM).

Language priors in Multimodal Large Language Models (MLLMs) refer to the inherent biases or preconceptions embedded in the language model component of an MLLM. These priors arise from the text data on which the language model was trained, influencing how the model interprets and generates language in conjunction with other modalities (e.g., images, audio). They can affect the model's predictions, leading to potential biases or expectations about the relationships between different types of data in multimodal contexts.

#### If you find this list useful, please :star it!

## Paper List

[VLind-Bench: Measuring Language Priors in Large Vision-Language Models](https://arxiv.org/abs/2406.08702)

[Debiasing Multimodal Large Language Models](https://arxiv.org/abs/2403.05262)

[Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding](https://arxiv.org/abs/2311.16922)

[Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding](https://arxiv.org/abs/2403.18715)
