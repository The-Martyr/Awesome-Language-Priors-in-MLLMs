# Awesome-Language-Priors-in-MLLMs

This is a repository for organizing papres related to language priors of Multimodal Large Language Models (MLLM).

Language priors in Multimodal Large Language Models (MLLMs) refer to the inherent biases or preconceptions embedded in the language model component of an MLLM. These priors arise from the text data on which the language model was trained, influencing how the model interprets and generates language in conjunction with other modalities (e.g., images, audio). They can affect the model's predictions, leading to potential biases or expectations about the relationships between different types of data in multimodal contexts.

#### :star: If you find this list useful, welcome to star it!

## Paper List (Updating...)

### Benchmark

(13 Jun 2024) [VLind-Bench: Measuring Language Priors in Large Vision-Language Models](https://arxiv.org/abs/2406.08702)

### Mitigate

(6 Apr 2024) [Context versus Prior Knowledge in Language Models](https://arxiv.org/abs/2404.04633)

(27 Mar 2024) [Mitigating Hallucinations in Large Vision-Language Models with Instruction Contrastive Decoding](https://arxiv.org/abs/2403.18715)

(8 Mar 2024) [Debiasing Multimodal Large Language Models](https://arxiv.org/abs/2403.05262)

(28 Nov 2023) [Mitigating Object Hallucinations in Large Vision-Language Models through Visual Contrastive Decoding](https://arxiv.org/abs/2311.16922)

### Related Works

(4 Jun 2024) [Eliciting the Priors of Large Language Models using Iterated In-Context Learning](https://arxiv.org/abs/2406.01860)

(25 Mar 2024) [The Strong Pull of Prior Knowledge in Large Language Models and Its Impact on Emotion Recognition](https://arxiv.org/abs/2403.17125)
